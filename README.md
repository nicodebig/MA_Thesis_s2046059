# RESPONSible Service: Evaluating Communication Styles in LLM-Generated Customer Service Interactions

This repository accompanies the thesis **"RESPONSible Service: Evaluating Communication Styles in LLM-Generated Customer Service Interactions"** by NicolÃ² de Bigontina, conducted at Leiden University. The project investigates how large language models (LLMs), specifically GPT-4o, express and differentiate between four key communication styles in customer service: **clarity, friendliness, empathy, and politeness**.

## ðŸ“ Repository Structure

```
.
â”œâ”€â”€ THESIS_CODE.ipynb                # Main analysis notebook
â”œâ”€â”€ concreteness_scores.txt          # Word-level concreteness values (for concreteness analysis)
â”œâ”€â”€ NGSL_1000.txt                    # First 1000 words from NGSL (for lexical complexity analysis)
â”œâ”€â”€ NGSL_2000.txt                    # Second 1000 words from NGSL (for lexical complexity analysis)
â”œâ”€â”€ requirements_1.txt               # Package requirements (for ICL and DPO text generation)
â”œâ”€â”€ requirements_2.txt               # Package requirements (for SFT text generation)
â”œâ”€â”€ requirements_3.txt               # Package requirements (for dataset generation and text overlap metrics)
â”œâ”€â”€ requirements_nlp.txt             # Package requirements (for linguistic data profiling)
â””â”€â”€ RESPONSible Service/             # Main dataset folder
    â”œâ”€â”€ dataset_clear.parquet        # CS interactions with clear style
    â”œâ”€â”€ dataset_friendly.parquet     # CS interactions with friendly style
    â”œâ”€â”€ dataset_empathetic.parquet   # CS interactions with empathetic style
    â”œâ”€â”€ dataset_polite.parquet       # CS interactions with polite style
```

## ðŸ“ Thesis Overview

The study presents the **RESPONSible Service** dataset, a synthetic collection of 4,000 customer service interactions generated by GPT-4o. Each interaction is labeled and written according to one of four predefined communication styles. The study includes:

- A description of the **generation methodology** used to create the RESPONSible Service dataset.
- A detailed **linguistic analysis**, examining features such as cohesion, sentiment, verb tense usage, formality, and concreteness.
- An assessment of **model performance** on text generation tasks using in-context learning, supervised fine-tuning, and direct preference optimization, all applied to the RESPONSible Service dataset.
- An **evaluation** of the generated outputs using BERTScore, ROUGE-L, and human agreement ratings.

Key findings include:
- Higher human agreement for friendliness, empathy, and politeness subsets than for clarity.
- Moderate alignment between the language patterns found in the generated data and the ones found in effective human customer service communication, with some occasional deviations.
- In-context learning outperformed other training methods in generating and preserving stylistic markedness in customer service responses.

## ðŸ“Š Usage

1. **Clone the repository**:
   ```bash
   git clone https://github.com/your-username/responsible-service.git
   cd responsible-service
   ```

2. **Install dependencies**:

   > âš ï¸ Dependencies are split across multiple files for modularity, and **some contain conflicting versions of the same packages**.  
   > **Only install the requirements file(s) corresponding to the module(s) you intend to run.**

   Use one of the following based on the part of the notebook you're working with:

   - `requirements_1.txt` â€” for **Text Generation Tasks using ICL and DPO**
   - `requirements_2.txt` â€” for **Text Generation Tasks using SFT**
   - `requirements_3.txt` â€” for **Dataset Generation** and **Text Generation Overlap Metrics**
   - `requirements_nlp.txt` â€” for **Linguistic Data Profiling**

   For example, to run the linguistic data profiling section:
   ```bash
   pip install -r requirements_nlp.txt
   ```

3. **Open and run the Jupyter notebook**:
   ```bash
   jupyter notebook THESIS_CODE.ipynb
   ```

## ðŸ“‚ Dataset: RESPONSible Service

Each `.parquet` file contains 1,000 customer service interactions focusing on one communication style. Each item has three fields:

- `request`: Customer query.
- `response0`: Initial LLM-generated customer service reply reflecting the target style.
- `response1`: A more stylistically marked version of `response0`.

## ðŸ“„ License and Ethics

- All data were **synthetically generated** using GPT-4o.
- The generated data are in English.
- No real customer data were used.
- The project complies with ethical standards for computational linguistics research.

## ðŸ“¬ Contact

For questions or collaboration inquiries, please contact:

**NicolÃ² de Bigontina**  
[Email](mailto:n.de.bigontina@umail.leidenuniv.nl)  
Leiden University, LUCL
