# RESPONSible Service: A Linguistic Analysis of LLMs in Customer Service

This repository accompanies the thesis **"The Role of Large Language Models in Customer Service: A Linguistic Analysis of Synthetically-Generated Customer Service Interactions"** by NicolÃ² de Bigontina, conducted at Leiden University. The project investigates how large language models (LLMs), specifically GPT-4o, express and differentiate between four key communication styles in customer service: **clarity, friendliness, empathy, and politeness**.

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ THESIS_CODE.ipynb                # Main analysis notebook
â”œâ”€â”€ concreteness_scores.txt          # Word-level concreteness values
â”œâ”€â”€ NGSL_1000.txt                    # First 1000 words from NGSL
â”œâ”€â”€ NGSL_2000.txt                    # Second 1000 words from NGSL
â”œâ”€â”€ requirements_1.txt               # Package requirements (subset 1)
â”œâ”€â”€ requirements_2.txt               # Package requirements (subset 2)
â”œâ”€â”€ requirements_3.txt               # Package requirements (subset 3)
â”œâ”€â”€ requirements_nlp.txt             # NLP-specific requirements
â””â”€â”€ RESPONSible Service/             # Main dataset folder
    â”œâ”€â”€ dataset_clear.parquet        # CS responses with clarity style
    â”œâ”€â”€ dataset_friendly.parquet     # CS responses with friendly style
    â”œâ”€â”€ dataset_empathetic.parquet   # CS responses with empathetic style
    â”œâ”€â”€ dataset_polite.parquet       # CS responses with polite style
```

## ğŸ“ Thesis Overview

The study introduces the **RESPONSible Service Dataset**, a synthetic corpus of 4,000 GPT-4o-generated customer service interactions, each labeled and styled according to one of the four communication modes. It includes:

- Detailed **linguistic profiling** using metrics such as cohesion, sentiment, deixis, formality, and concreteness.
- Evaluation of model performance on stylistic generation using in-context learning, supervised fine-tuning, and direct preference optimization.
- Comparison of outputs using BERTScore and ROUGE-L.

Key findings include:
- **High human agreement** for friendliness, empathy, and politeness subsets.
- **Clarity** emerged as the most unpredictable and challenging style to model.
- **In-context learning** outperformed other training methods in generating stylistically appropriate responses.

## ğŸ“Š Usage

To explore or reproduce the analysis:

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/responsible-service.git
   cd responsible-service
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements_nlp.txt
   ```

3. Open and run the Jupyter notebook:
   ```bash
   jupyter notebook THESIS_CODE.ipynb
   ```

## ğŸ“‚ Dataset: RESPONSible Service

Each `.parquet` file contains 1,000 customer service interactions focusing on one communication style. Each item has three fields:

- `request`: Customer query.
- `response0`: Initial LLM-generated reply reflecting the target style.
- `response1`: A more stylistically marked version of `response0`.

## ğŸ”§ Requirements

Dependencies are split across several requirements files for modularity:

- `requirements_1.txt`, `requirements_2.txt`, `requirements_3.txt`: General dependencies (e.g., pandas, matplotlib, sklearn).
- `requirements_nlp.txt`: Dependencies for the linguistic data profiling section.

## ğŸ“„ License and Ethics

- All data were **synthetically generated** using GPT-4o.
- No real customer data was used.
- The project complies with ethical standards for computational linguistics research.

## ğŸ“¬ Contact

For questions or collaboration inquiries, please contact:

**NicolÃ² de Bigontina**  
[Email](mailto:n.de.bigontina@umail.leidenuniv.nl)  
Leiden University, LUCL
